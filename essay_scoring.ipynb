{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "33688391",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33688391",
        "outputId": "cbcf8404-8953-4780-a069-88f4885c8cc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing necessary libraries and packages\n",
        "\n",
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn import ensemble\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import (\n",
        "    cohen_kappa_score,\n",
        "    explained_variance_score,\n",
        "    mean_squared_error,\n",
        ")\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0306a017",
      "metadata": {
        "id": "0306a017"
      },
      "outputs": [],
      "source": [
        "def download_dataset_file(url, destination_path):\n",
        "    \"\"\"\n",
        "    Downloads a file from the specified URL and saves it to the given path.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(destination_path):\n",
        "        response = requests.get(url)\n",
        "        with open(destination_path, \"wb\") as file:\n",
        "            file.write(response.content)\n",
        "\n",
        "\n",
        "# Create a directory for the dataset\n",
        "os.makedirs(\"Dataset\", exist_ok=True)\n",
        "\n",
        "download_dataset_file(\n",
        "    \"https://www.dropbox.com/scl/fi/0s4skjwowniwy1pn3uwaz/essay_scorer_dataset.zip?rlkey=uhcmx6z82llbkc7hs24ww97fl&st=l55tyxi3&dl=1\",\n",
        "    \"Dataset/essay_scorer_dataset.zip\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1aeebf77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aeebf77",
        "outputId": "d9b38cd2-0540-49d1-f5ae-c85026a8734e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction completed successfully.\n"
          ]
        }
      ],
      "source": [
        "# Function to unzip the dataset file\n",
        "def extract_zip_file(zip_file_path=None):\n",
        "    \"\"\"\n",
        "    Extracts the contents of a zip file into the 'Dataset' directory.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file_path, \"r\") as z:\n",
        "            z.extractall(\"Dataset\")\n",
        "            print(\"Extraction completed successfully.\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(\"Error: Invalid zip file provided.\")\n",
        "\n",
        "\n",
        "extract_zip_file(\"Dataset/essay_scorer_dataset.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "21dc8588",
      "metadata": {
        "id": "21dc8588"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "training_data = pd.read_csv(\"Dataset/training_set.tsv\", sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
        "\n",
        "# Extract dependent variable\n",
        "target_scores = training_data[\"domain1_score\"]\n",
        "essays_df = training_data.loc[:, [\"essay_id\", \"essay_set\", \"essay\", \"domain1_score\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cdfec98d",
      "metadata": {
        "id": "cdfec98d",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "# Tokenize words from essays after cleaning text by removing non-alphabetic characters,\n",
        "# converting to lowercase, and removing stopwords\n",
        "\n",
        "\n",
        "def tokenize_words(essay_text):\n",
        "    \"\"\"\n",
        "    Cleans and tokenizes words from the provided essay text.\n",
        "    \"\"\"\n",
        "    clean_text = re.sub(\"[^a-zA-Z]\", \" \", essay_text)\n",
        "    words = clean_text.lower().split()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_words = [w for w in words if w not in stop_words]\n",
        "    return filtered_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf7d4617",
      "metadata": {
        "id": "cf7d4617",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "# Tokenize sentences from essays and subsequently tokenize words within those sentences\n",
        "\n",
        "\n",
        "def tokenize_sentences(essay_text):\n",
        "    \"\"\"\n",
        "    Tokenizes sentences from the provided essay text, and then tokenizes words within those sentences.\n",
        "    \"\"\"\n",
        "    tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
        "    sentences = tokenizer.tokenize(essay_text.strip())\n",
        "    tokenized_sentences = [\n",
        "        tokenize_words(sentence) for sentence in sentences if len(sentence) > 0\n",
        "    ]\n",
        "    return tokenized_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fa96f316",
      "metadata": {
        "id": "fa96f316",
        "lines_to_next_cell": 2
      },
      "outputs": [],
      "source": [
        "# Generate a feature vector for the provided words\n",
        "\n",
        "\n",
        "def generate_feature_vector(words, model, num_features):\n",
        "    \"\"\"\n",
        "    Generates a feature vector by averaging word vectors from the provided word list.\n",
        "    \"\"\"\n",
        "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
        "    num_words = 0.0\n",
        "    model_vocab = set(model.wv.index_to_key)\n",
        "\n",
        "    for word in words:\n",
        "        if word in model_vocab:\n",
        "            num_words += 1\n",
        "            feature_vector = np.add(feature_vector, model.wv[word])\n",
        "\n",
        "    if num_words > 0:\n",
        "        feature_vector = np.divide(feature_vector, num_words)\n",
        "\n",
        "    return feature_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cf510db2",
      "metadata": {
        "id": "cf510db2"
      },
      "outputs": [],
      "source": [
        "# Generate average feature vectors for a list of essays\n",
        "\n",
        "\n",
        "def generate_avg_feature_vectors(essays, model, num_features):\n",
        "    \"\"\"\n",
        "    Generates average feature vectors for each essay in the list of essays.\n",
        "    \"\"\"\n",
        "    essay_feature_vectors = np.zeros((len(essays), num_features), dtype=\"float32\")\n",
        "\n",
        "    for i, essay_text in enumerate(essays):\n",
        "        essay_feature_vectors[i] = generate_feature_vector(\n",
        "            essay_text, model, num_features\n",
        "        )\n",
        "\n",
        "    return essay_feature_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "409abec2",
      "metadata": {
        "id": "409abec2"
      },
      "outputs": [],
      "source": [
        "def build_lstm_model():\n",
        "    \"\"\"\n",
        "    Builds and compiles an LSTM model for essay scoring.\n",
        "    \"\"\"\n",
        "    lstm_model = Sequential()\n",
        "    lstm_model.add(\n",
        "        LSTM(\n",
        "            300,\n",
        "            dropout=0.4,\n",
        "            recurrent_dropout=0.4,\n",
        "            input_shape=[1, 300],\n",
        "            return_sequences=True,\n",
        "        )\n",
        "    )\n",
        "    lstm_model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    lstm_model.add(Dropout(0.5))\n",
        "    lstm_model.add(Dense(1, activation=\"relu\"))\n",
        "\n",
        "    lstm_model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\", metrics=[\"mae\"])\n",
        "    lstm_model.summary()\n",
        "\n",
        "    return lstm_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "244225df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "244225df",
        "outputId": "94f7eee7-604f-44f7-a843-6b054cdae82e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------ Fold 1 ------------\n",
            "\n",
            "Training Word2Vec model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-e0cf2889299e>:42: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  word2vec_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)              │         \u001b[38;5;34m721,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m93,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 95.8304 - mae: 5.3998\n",
            "Epoch 2/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 45.2673 - mae: 3.7406\n",
            "Epoch 3/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 37.9313 - mae: 3.6536\n",
            "Epoch 4/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 31.9347 - mae: 3.5094\n",
            "Epoch 5/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 30.2155 - mae: 3.3645\n",
            "Epoch 6/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 27.3598 - mae: 3.0954\n",
            "Epoch 7/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 26.7014 - mae: 3.0206\n",
            "Epoch 8/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 21.9366 - mae: 2.7214\n",
            "Epoch 9/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 19.0788 - mae: 2.5200\n",
            "Epoch 10/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 17.5852 - mae: 2.4091\n",
            "Epoch 11/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 17.0019 - mae: 2.3605\n",
            "Epoch 12/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 15.0781 - mae: 2.2383\n",
            "Epoch 13/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 15.1546 - mae: 2.2127\n",
            "Epoch 14/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 14.9422 - mae: 2.1934\n",
            "Epoch 15/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 13.4885 - mae: 2.1093\n",
            "Epoch 16/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 13.4769 - mae: 2.0546\n",
            "Epoch 17/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 13.2501 - mae: 2.0664\n",
            "Epoch 18/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 13.5280 - mae: 2.0297\n",
            "Epoch 19/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.6535 - mae: 1.9296\n",
            "Epoch 20/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 11.3485 - mae: 1.9122\n",
            "Epoch 21/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 12.3128 - mae: 1.9634\n",
            "Epoch 22/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 11.3141 - mae: 1.8660\n",
            "Epoch 23/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 10.6489 - mae: 1.8319\n",
            "Epoch 24/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 10.9608 - mae: 1.8550\n",
            "Epoch 25/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.8377 - mae: 1.7636\n",
            "Epoch 26/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 10.9719 - mae: 1.8457\n",
            "Epoch 27/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.6906 - mae: 1.7508\n",
            "Epoch 28/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 10.1366 - mae: 1.7980\n",
            "Epoch 29/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 10.4214 - mae: 1.8013\n",
            "Epoch 30/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 10.2017 - mae: 1.7873\n",
            "Epoch 31/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 10.4526 - mae: 1.7918\n",
            "Epoch 32/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.8823 - mae: 1.7648\n",
            "Epoch 33/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.7224 - mae: 1.7600\n",
            "Epoch 34/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 9.8736 - mae: 1.7381\n",
            "Epoch 35/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 9.1670 - mae: 1.7382\n",
            "Epoch 36/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.4821 - mae: 1.7309\n",
            "Epoch 37/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.1384 - mae: 1.7134\n",
            "Epoch 38/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7763 - mae: 1.6809\n",
            "Epoch 39/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.4805 - mae: 1.6824\n",
            "Epoch 40/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8.2736 - mae: 1.6478\n",
            "Epoch 41/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7055 - mae: 1.6961\n",
            "Epoch 42/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.2131 - mae: 1.7084\n",
            "Epoch 43/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 9.2881 - mae: 1.7269\n",
            "Epoch 44/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.6608 - mae: 1.6499\n",
            "Epoch 45/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8.5356 - mae: 1.6469\n",
            "Epoch 46/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3040 - mae: 1.7034\n",
            "Epoch 47/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.8453 - mae: 1.6807\n",
            "Epoch 48/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 8.7602 - mae: 1.6553\n",
            "Epoch 49/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 8.2582 - mae: 1.6533\n",
            "Epoch 50/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.3397 - mae: 1.6897\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Mean squared error: 7.10\n",
            "Explained variance score: 0.91\n",
            "Cohen's Kappa Score: 0.95\n",
            "\n",
            "------------ Fold 2 ------------\n",
            "\n",
            "Training Word2Vec model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-e0cf2889299e>:42: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  word2vec_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)              │         \u001b[38;5;34m721,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m93,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 87.4932 - mae: 5.2520\n",
            "Epoch 2/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 45.7191 - mae: 3.7325\n",
            "Epoch 3/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 35.7320 - mae: 3.5276\n",
            "Epoch 4/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 30.6826 - mae: 3.3705\n",
            "Epoch 5/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 30.7478 - mae: 3.3536\n",
            "Epoch 6/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 30.5234 - mae: 3.1944\n",
            "Epoch 7/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 26.5052 - mae: 2.9648\n",
            "Epoch 8/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 22.1246 - mae: 2.7226\n",
            "Epoch 9/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 20.7486 - mae: 2.5893\n",
            "Epoch 10/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 17.4436 - mae: 2.3671\n",
            "Epoch 11/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 17.3047 - mae: 2.3836\n",
            "Epoch 12/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 16.4160 - mae: 2.3454\n",
            "Epoch 13/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 14.6204 - mae: 2.1731\n",
            "Epoch 14/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 14.4346 - mae: 2.1826\n",
            "Epoch 15/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 14.7356 - mae: 2.1561\n",
            "Epoch 16/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 13.9942 - mae: 2.0945\n",
            "Epoch 17/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 12.1472 - mae: 1.9930\n",
            "Epoch 18/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.8321 - mae: 1.9640\n",
            "Epoch 19/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 12.5393 - mae: 1.9624\n",
            "Epoch 20/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 12.6990 - mae: 1.9898\n",
            "Epoch 21/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.1067 - mae: 1.8918\n",
            "Epoch 22/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 11.0802 - mae: 1.8822\n",
            "Epoch 23/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 11.6187 - mae: 1.8710\n",
            "Epoch 24/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 9.2164 - mae: 1.7221\n",
            "Epoch 25/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 10.8496 - mae: 1.8336\n",
            "Epoch 26/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.6584 - mae: 1.9001\n",
            "Epoch 27/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4436 - mae: 1.7413\n",
            "Epoch 28/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 10.7716 - mae: 1.8062\n",
            "Epoch 29/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 10.9347 - mae: 1.8148\n",
            "Epoch 30/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 10.3498 - mae: 1.7903\n",
            "Epoch 31/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 10.0074 - mae: 1.7803\n",
            "Epoch 32/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.7618 - mae: 1.7849\n",
            "Epoch 33/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 9.6191 - mae: 1.7667\n",
            "Epoch 34/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.6825 - mae: 1.7534\n",
            "Epoch 35/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3640 - mae: 1.7393\n",
            "Epoch 36/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.6503 - mae: 1.7700\n",
            "Epoch 37/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7281 - mae: 1.6652\n",
            "Epoch 38/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.4713 - mae: 1.7268\n",
            "Epoch 39/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.1147 - mae: 1.6850\n",
            "Epoch 40/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4080 - mae: 1.7232\n",
            "Epoch 41/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.7261 - mae: 1.7294\n",
            "Epoch 42/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 8.7546 - mae: 1.6751\n",
            "Epoch 43/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 9.2740 - mae: 1.7056\n",
            "Epoch 44/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.8979 - mae: 1.6114\n",
            "Epoch 45/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9295 - mae: 1.6872\n",
            "Epoch 46/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7306 - mae: 1.6573\n",
            "Epoch 47/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9165 - mae: 1.6487\n",
            "Epoch 48/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.7345 - mae: 1.6660\n",
            "Epoch 49/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 8.3841 - mae: 1.6410\n",
            "Epoch 50/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 9.5063 - mae: 1.7352\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Mean squared error: 6.79\n",
            "Explained variance score: 0.92\n",
            "Cohen's Kappa Score: 0.95\n",
            "\n",
            "------------ Fold 3 ------------\n",
            "\n",
            "Training Word2Vec model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-e0cf2889299e>:42: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  word2vec_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)              │         \u001b[38;5;34m721,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m93,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 87.3216 - mae: 5.2189\n",
            "Epoch 2/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 46.1491 - mae: 3.8168\n",
            "Epoch 3/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 37.1777 - mae: 3.6397\n",
            "Epoch 4/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 32.9034 - mae: 3.5224\n",
            "Epoch 5/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 29.6104 - mae: 3.3094\n",
            "Epoch 6/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 27.0232 - mae: 3.0984\n",
            "Epoch 7/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 25.8922 - mae: 2.9540\n",
            "Epoch 8/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 22.2884 - mae: 2.7144\n",
            "Epoch 9/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 19.8395 - mae: 2.5474\n",
            "Epoch 10/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 18.9615 - mae: 2.4689\n",
            "Epoch 11/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 16.4886 - mae: 2.3129\n",
            "Epoch 12/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 16.0226 - mae: 2.2888\n",
            "Epoch 13/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 14.2582 - mae: 2.1568\n",
            "Epoch 14/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 14.7628 - mae: 2.1800\n",
            "Epoch 15/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 13.4853 - mae: 2.1166\n",
            "Epoch 16/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 13.1926 - mae: 2.0451\n",
            "Epoch 17/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 13.4604 - mae: 2.0492\n",
            "Epoch 18/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 12.3508 - mae: 1.9877\n",
            "Epoch 19/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 12.5450 - mae: 1.9935\n",
            "Epoch 20/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.7395 - mae: 1.9272\n",
            "Epoch 21/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 11.8376 - mae: 1.9194\n",
            "Epoch 22/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 10.8778 - mae: 1.8501\n",
            "Epoch 23/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 11.4286 - mae: 1.8727\n",
            "Epoch 24/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 10.8164 - mae: 1.8118\n",
            "Epoch 25/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 10.3083 - mae: 1.7947\n",
            "Epoch 26/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 11.6320 - mae: 1.8689\n",
            "Epoch 27/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 11.2337 - mae: 1.8307\n",
            "Epoch 28/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.2807 - mae: 1.7958\n",
            "Epoch 29/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.8692 - mae: 1.7692\n",
            "Epoch 30/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 10.8917 - mae: 1.8239\n",
            "Epoch 31/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 11.4638 - mae: 1.8347\n",
            "Epoch 32/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.4354 - mae: 1.7887\n",
            "Epoch 33/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.8314 - mae: 1.7610\n",
            "Epoch 34/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5233 - mae: 1.7501\n",
            "Epoch 35/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.3898 - mae: 1.7290\n",
            "Epoch 36/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 9.4644 - mae: 1.7267\n",
            "Epoch 37/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 9.5877 - mae: 1.7166\n",
            "Epoch 38/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.8419 - mae: 1.7022\n",
            "Epoch 39/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4214 - mae: 1.7093\n",
            "Epoch 40/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.8382 - mae: 1.6744\n",
            "Epoch 41/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 8.7288 - mae: 1.6635\n",
            "Epoch 42/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 9.7279 - mae: 1.7456\n",
            "Epoch 43/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 9.0878 - mae: 1.6968\n",
            "Epoch 44/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 9.6660 - mae: 1.7046\n",
            "Epoch 45/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.9869 - mae: 1.6990\n",
            "Epoch 46/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 8.8124 - mae: 1.6422\n",
            "Epoch 47/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8.7396 - mae: 1.6584\n",
            "Epoch 48/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.1444 - mae: 1.6688\n",
            "Epoch 49/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.2115 - mae: 1.6892\n",
            "Epoch 50/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 9.5575 - mae: 1.6968\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Mean squared error: 6.98\n",
            "Explained variance score: 0.92\n",
            "Cohen's Kappa Score: 0.96\n",
            "\n",
            "------------ Fold 4 ------------\n",
            "\n",
            "Training Word2Vec model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-e0cf2889299e>:42: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  word2vec_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)              │         \u001b[38;5;34m721,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m93,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 87.0792 - mae: 5.1896\n",
            "Epoch 2/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 42.0736 - mae: 3.6845\n",
            "Epoch 3/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 33.5755 - mae: 3.4645\n",
            "Epoch 4/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 32.9684 - mae: 3.5781\n",
            "Epoch 5/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 28.0450 - mae: 3.2673\n",
            "Epoch 6/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 27.3234 - mae: 3.0977\n",
            "Epoch 7/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 25.7078 - mae: 2.9767\n",
            "Epoch 8/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 21.8448 - mae: 2.6973\n",
            "Epoch 9/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 18.0025 - mae: 2.4390\n",
            "Epoch 10/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 18.2784 - mae: 2.4296\n",
            "Epoch 11/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 16.8068 - mae: 2.3296\n",
            "Epoch 12/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 16.1825 - mae: 2.2908\n",
            "Epoch 13/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 15.1577 - mae: 2.1953\n",
            "Epoch 14/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 15.8138 - mae: 2.2127\n",
            "Epoch 15/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 15.2748 - mae: 2.1588\n",
            "Epoch 16/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 14.4489 - mae: 2.0884\n",
            "Epoch 17/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 13.2435 - mae: 2.0319\n",
            "Epoch 18/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 13.8738 - mae: 2.0556\n",
            "Epoch 19/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 12.1626 - mae: 1.9866\n",
            "Epoch 20/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 12.9281 - mae: 1.9520\n",
            "Epoch 21/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 12.1535 - mae: 1.9027\n",
            "Epoch 22/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 11.8635 - mae: 1.9052\n",
            "Epoch 23/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 12.0389 - mae: 1.9169\n",
            "Epoch 24/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 12.5220 - mae: 1.9049\n",
            "Epoch 25/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 11.5520 - mae: 1.8441\n",
            "Epoch 26/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 11.2300 - mae: 1.8209\n",
            "Epoch 27/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.8597 - mae: 1.8096\n",
            "Epoch 28/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.2178 - mae: 1.8480\n",
            "Epoch 29/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 11.3249 - mae: 1.8318\n",
            "Epoch 30/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 11.6653 - mae: 1.8076\n",
            "Epoch 31/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 10.5442 - mae: 1.7778\n",
            "Epoch 32/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 10.5643 - mae: 1.8104\n",
            "Epoch 33/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.4292 - mae: 1.8140\n",
            "Epoch 34/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 10.2125 - mae: 1.7655\n",
            "Epoch 35/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 10.6583 - mae: 1.7809\n",
            "Epoch 36/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 10.5121 - mae: 1.7603\n",
            "Epoch 37/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 10.4383 - mae: 1.7815\n",
            "Epoch 38/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 10.0726 - mae: 1.7411\n",
            "Epoch 39/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4020 - mae: 1.7067\n",
            "Epoch 40/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 10.1134 - mae: 1.7534\n",
            "Epoch 41/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 9.5014 - mae: 1.6984\n",
            "Epoch 42/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.8158 - mae: 1.7145\n",
            "Epoch 43/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 9.1281 - mae: 1.6934\n",
            "Epoch 44/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5120 - mae: 1.6908\n",
            "Epoch 45/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.6013 - mae: 1.6461\n",
            "Epoch 46/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 8.6685 - mae: 1.6574\n",
            "Epoch 47/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 9.7613 - mae: 1.7101\n",
            "Epoch 48/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.1804 - mae: 1.6802\n",
            "Epoch 49/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.7606 - mae: 1.6367\n",
            "Epoch 50/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 9.4567 - mae: 1.7004\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "Mean squared error: 5.38\n",
            "Explained variance score: 0.93\n",
            "Cohen's Kappa Score: 0.97\n",
            "\n",
            "------------ Fold 5 ------------\n",
            "\n",
            "Training Word2Vec model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-e0cf2889299e>:42: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  word2vec_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)              │         \u001b[38;5;34m721,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m93,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">814,705</span> (3.11 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m814,705\u001b[0m (3.11 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 82.7172 - mae: 5.0215\n",
            "Epoch 2/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 44.1996 - mae: 3.7179\n",
            "Epoch 3/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 33.5021 - mae: 3.4335\n",
            "Epoch 4/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 30.0571 - mae: 3.3565\n",
            "Epoch 5/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 28.8367 - mae: 3.3017\n",
            "Epoch 6/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 25.5255 - mae: 3.0147\n",
            "Epoch 7/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 23.2486 - mae: 2.8455\n",
            "Epoch 8/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 21.7273 - mae: 2.6986\n",
            "Epoch 9/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 18.9414 - mae: 2.4890\n",
            "Epoch 10/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 18.2570 - mae: 2.4121\n",
            "Epoch 11/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 14.9675 - mae: 2.1880\n",
            "Epoch 12/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 14.8774 - mae: 2.2026\n",
            "Epoch 13/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 14.4245 - mae: 2.1594\n",
            "Epoch 14/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 14.6305 - mae: 2.1513\n",
            "Epoch 15/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 12.3983 - mae: 2.0249\n",
            "Epoch 16/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 11.9587 - mae: 1.9843\n",
            "Epoch 17/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 12.2487 - mae: 1.9633\n",
            "Epoch 18/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 12.5432 - mae: 1.9703\n",
            "Epoch 19/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 12.3188 - mae: 1.9644\n",
            "Epoch 20/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 12.0459 - mae: 1.9285\n",
            "Epoch 21/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 11.4506 - mae: 1.9050\n",
            "Epoch 22/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 10.7151 - mae: 1.8457\n",
            "Epoch 23/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 10.5454 - mae: 1.8127\n",
            "Epoch 24/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.8999 - mae: 1.8310\n",
            "Epoch 25/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 10.8809 - mae: 1.8349\n",
            "Epoch 26/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 10.3589 - mae: 1.7995\n",
            "Epoch 27/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 10.0140 - mae: 1.7871\n",
            "Epoch 28/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 10.4940 - mae: 1.8007\n",
            "Epoch 29/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.1534 - mae: 1.7818\n",
            "Epoch 30/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 9.2327 - mae: 1.6993\n",
            "Epoch 31/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 9.4029 - mae: 1.7198\n",
            "Epoch 32/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 8.9490 - mae: 1.6981\n",
            "Epoch 33/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.1431 - mae: 1.7038\n",
            "Epoch 34/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 9.7949 - mae: 1.7604\n",
            "Epoch 35/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.9788 - mae: 1.7085\n",
            "Epoch 36/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.1738 - mae: 1.6969\n",
            "Epoch 37/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7768 - mae: 1.6706\n",
            "Epoch 38/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.8042 - mae: 1.7105\n",
            "Epoch 39/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 8.9078 - mae: 1.6980\n",
            "Epoch 40/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.8959 - mae: 1.6875\n",
            "Epoch 41/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.1505 - mae: 1.6805\n",
            "Epoch 42/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.0166 - mae: 1.6838\n",
            "Epoch 43/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 9.6735 - mae: 1.7050\n",
            "Epoch 44/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 8.6316 - mae: 1.6528\n",
            "Epoch 45/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8.6052 - mae: 1.6521\n",
            "Epoch 46/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 8.8167 - mae: 1.6718\n",
            "Epoch 47/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 9.0142 - mae: 1.6729\n",
            "Epoch 48/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 8.1544 - mae: 1.6085\n",
            "Epoch 49/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 8.8115 - mae: 1.6661\n",
            "Epoch 50/50\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 8.4459 - mae: 1.6264\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
            "Mean squared error: 5.80\n",
            "Explained variance score: 0.93\n",
            "Cohen's Kappa Score: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Applying k-fold cross-validation\n",
        "\n",
        "cross_validator = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "evaluation_results = []\n",
        "predicted_scores = []\n",
        "\n",
        "fold_counter = 1\n",
        "for train_indices, test_indices in cross_validator.split(essays_df):\n",
        "\n",
        "    print(\"\\n------------ Fold {} ------------\\n\".format(fold_counter))\n",
        "    train_set, test_set = essays_df.iloc[train_indices], essays_df.iloc[test_indices]\n",
        "    y_train, y_test = (\n",
        "        target_scores.iloc[train_indices],\n",
        "        target_scores.iloc[test_indices],\n",
        "    )\n",
        "\n",
        "    train_essays = train_set[\"essay\"]\n",
        "    test_essays = test_set[\"essay\"]\n",
        "\n",
        "    # Tokenize sentences from training essays\n",
        "    all_sentences = []\n",
        "    for essay in train_essays:\n",
        "        all_sentences += tokenize_sentences(essay)\n",
        "\n",
        "    # Word2Vec model parameters\n",
        "    vector_size = 300\n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context_window = 10\n",
        "    downsampling = 1e-3\n",
        "\n",
        "    print(\"Training Word2Vec model...\")\n",
        "    word2vec_model = Word2Vec(\n",
        "        all_sentences,\n",
        "        workers=num_workers,\n",
        "        vector_size=vector_size,\n",
        "        min_count=min_word_count,\n",
        "        window=context_window,\n",
        "        sample=downsampling,\n",
        "    )\n",
        "\n",
        "    word2vec_model.init_sims(replace=True)\n",
        "    word2vec_model.wv.save_word2vec_format(\"word2vec_model.bin\", binary=True)\n",
        "\n",
        "    # Generate feature vectors for training and testing sets\n",
        "    clean_train_essays = [tokenize_words(essay) for essay in train_essays]\n",
        "    train_data_vectors = generate_avg_feature_vectors(\n",
        "        clean_train_essays, word2vec_model, vector_size\n",
        "    )\n",
        "\n",
        "    clean_test_essays = [tokenize_words(essay) for essay in test_essays]\n",
        "    test_data_vectors = generate_avg_feature_vectors(\n",
        "        clean_test_essays, word2vec_model, vector_size\n",
        "    )\n",
        "\n",
        "    train_data_vectors = np.reshape(\n",
        "        train_data_vectors,\n",
        "        (train_data_vectors.shape[0], 1, train_data_vectors.shape[1]),\n",
        "    )\n",
        "    test_data_vectors = np.reshape(\n",
        "        test_data_vectors, (test_data_vectors.shape[0], 1, test_data_vectors.shape[1])\n",
        "    )\n",
        "\n",
        "    lstm_model = build_lstm_model()\n",
        "    lstm_model.fit(train_data_vectors, y_train, batch_size=64, epochs=50)\n",
        "    predicted_y = lstm_model.predict(test_data_vectors)\n",
        "\n",
        "    # Round predicted values to nearest integer\n",
        "    predicted_y = np.around(predicted_y)\n",
        "\n",
        "    \"\"\"Evaluation metrics used:\n",
        "    1. Mean squared error\n",
        "    2. Explained variance score\n",
        "    3. Cohen's kappa score\n",
        "    Expected results: Minimum error, maximum variance, and maximum kappa score.\"\"\"\n",
        "\n",
        "    # Mean squared error\n",
        "    print(\n",
        "        \"Mean squared error: {0:.2f}\".format(\n",
        "            mean_squared_error(y_test.values, predicted_y)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Explained variance score\n",
        "    print(\n",
        "        \"Explained variance score: {0:.2f}\".format(\n",
        "            explained_variance_score(y_test.values, predicted_y)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Cohen's kappa score\n",
        "    kappa_score = cohen_kappa_score(y_test.values, predicted_y, weights=\"quadratic\")\n",
        "    print(\"Cohen's Kappa Score: {0:.2f}\".format(kappa_score))\n",
        "    evaluation_results.append(kappa_score)\n",
        "\n",
        "    fold_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "80d0a6b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80d0a6b2",
        "outputId": "6aad1be2-62de-4a01-bfd2-fd506c233026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Cohen's Kappa score after 5-fold cross-validation:  0.96\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"Average Cohen's Kappa score after 5-fold cross-validation: \",\n",
        "    np.around(np.mean(evaluation_results), decimals=2),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b3afb798",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3afb798",
        "outputId": "ede431ff-0e63-4267-a4b3-e2161591a0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Word2Vec Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-06458ca5ae4b>:32: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  word2vec_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        }
      ],
      "source": [
        "# Splitting dataset into training and test set and generating word embeddings for other models\n",
        "\n",
        "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
        "    training_data, target_scores, test_size=0.25\n",
        ")\n",
        "\n",
        "train_essays_split = X_train_split[\"essay\"]\n",
        "test_essays_split = X_test_split[\"essay\"]\n",
        "\n",
        "sentences_split = []\n",
        "\n",
        "for essay_split in train_essays_split:\n",
        "    sentences_split += tokenize_sentences(essay_split)\n",
        "\n",
        "# Initializing variables for Word2Vec model\n",
        "num_features = 300\n",
        "min_word_count = 40\n",
        "num_workers = 4\n",
        "context = 10\n",
        "downsampling = 1e-3\n",
        "\n",
        "print(\"Training Word2Vec Model...\")\n",
        "word2vec_model = Word2Vec(\n",
        "    sentences_split,\n",
        "    workers=num_workers,\n",
        "    vector_size=num_features,\n",
        "    min_count=min_word_count,\n",
        "    window=context,\n",
        "    sample=downsampling,\n",
        ")\n",
        "\n",
        "word2vec_model.init_sims(replace=True)\n",
        "word2vec_model.wv.save_word2vec_format(\"word2vec_model.bin\", binary=True)\n",
        "\n",
        "clean_train_essays_split = []\n",
        "\n",
        "# Generate training and testing data word vectors\n",
        "for essay_text_split in train_essays_split:\n",
        "    clean_train_essays_split.append(tokenize_words(essay_text_split))\n",
        "trainDataVecs_split = generate_avg_feature_vectors(\n",
        "    clean_train_essays_split, word2vec_model, num_features\n",
        ")\n",
        "\n",
        "clean_test_essays_split = []\n",
        "for essay_text_split in test_essays_split:\n",
        "    clean_test_essays_split.append(tokenize_words(essay_text_split))\n",
        "testDataVecs_split = generate_avg_feature_vectors(\n",
        "    clean_test_essays_split, word2vec_model, num_features\n",
        ")\n",
        "\n",
        "trainDataVecs_split = np.array(trainDataVecs_split)\n",
        "testDataVecs_split = np.array(testDataVecs_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "400fd05a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "400fd05a",
        "outputId": "6cc5d386-116b-43aa-b8c6-156c7b01d316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean squared error: 19.76\n",
            "Variance score: 0.75\n",
            "Kappa Score: 0.86\n"
          ]
        }
      ],
      "source": [
        "# Generating scores using Linear Regression Model\n",
        "\n",
        "linear_regressor_split = LinearRegression()\n",
        "\n",
        "linear_regressor_split.fit(trainDataVecs_split, y_train_split)\n",
        "\n",
        "y_pred_split = linear_regressor_split.predict(testDataVecs_split)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_split, y_pred_split))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print(\"Variance score: %.2f\" % explained_variance_score(y_test_split, y_pred_split))\n",
        "\n",
        "# Cohen's kappa score\n",
        "print(\n",
        "    \"Kappa Score: {0:.2f}\".format(\n",
        "        cohen_kappa_score(\n",
        "            y_test_split.values, np.around(y_pred_split), weights=\"quadratic\"\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "292ce38b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "292ce38b",
        "outputId": "e39883be-64a3-4d30-fd0e-a526111b9db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean squared error: 6.83\n",
            "Variance score: 0.91\n",
            "Kappa Score: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Generating scores using Gradient Boosting Regressor\n",
        "\n",
        "gbr_split = ensemble.GradientBoostingRegressor(\n",
        "    alpha=0.9,\n",
        "    criterion=\"friedman_mse\",\n",
        "    init=None,\n",
        "    learning_rate=0.1,\n",
        "    loss=\"squared_error\",\n",
        "    max_depth=2,\n",
        "    max_features=None,\n",
        "    max_leaf_nodes=None,\n",
        "    min_impurity_decrease=0.0,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=2,\n",
        "    min_weight_fraction_leaf=0.0,\n",
        "    n_estimators=1000,\n",
        "    random_state=None,\n",
        "    subsample=1.0,\n",
        "    verbose=0,\n",
        "    warm_start=False,\n",
        ")\n",
        "gbr_split.fit(trainDataVecs_split, y_train_split)\n",
        "y_pred_split = gbr_split.predict(testDataVecs_split)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_split, y_pred_split))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print(\"Variance score: %.2f\" % explained_variance_score(y_test_split, y_pred_split))\n",
        "\n",
        "# Cohen's kappa score\n",
        "print(\n",
        "    \"Kappa Score: {0:.2f}\".format(\n",
        "        cohen_kappa_score(\n",
        "            y_test_split.values, np.around(y_pred_split), weights=\"quadratic\"\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "56b88175",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56b88175",
        "outputId": "e513cdf4-b866-496d-c354-32db45c5e0da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean squared error: 28.94\n",
            "Variance score: 0.64\n",
            "Kappa Score: 0.74\n"
          ]
        }
      ],
      "source": [
        "# Generating scores using Support Vector Regression (SVR)\n",
        "\n",
        "svr_split = SVR(\n",
        "    C=100,\n",
        "    cache_size=200,\n",
        "    coef0=0.0,\n",
        "    degree=3,\n",
        "    epsilon=0.1,\n",
        "    gamma=0.1,\n",
        "    kernel=\"rbf\",\n",
        "    max_iter=-1,\n",
        "    shrinking=True,\n",
        "    tol=0.001,\n",
        "    verbose=False,\n",
        ")\n",
        "svr_split.fit(trainDataVecs_split, y_train_split)\n",
        "y_pred_split = svr_split.predict(testDataVecs_split)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test_split, y_pred_split))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print(\"Variance score: %.2f\" % explained_variance_score(y_test_split, y_pred_split))\n",
        "\n",
        "# Cohen's kappa score\n",
        "print(\n",
        "    \"Kappa Score: {0:.2f}\".format(\n",
        "        cohen_kappa_score(\n",
        "            y_test_split.values, np.around(y_pred_split), weights=\"quadratic\"\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4322d664",
      "metadata": {
        "id": "4322d664"
      },
      "outputs": [],
      "source": [
        "# As LSTM outperforms all other models, using it for predicting the scores for the final dataset\n",
        "validation_set = pd.read_csv(\"Dataset/valid_set.tsv\", sep=\"\\t\", encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5a599b31",
      "metadata": {
        "id": "5a599b31"
      },
      "outputs": [],
      "source": [
        "validation_set = validation_set.drop([\"domain2_predictionid\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a8a15694",
      "metadata": {
        "id": "a8a15694"
      },
      "outputs": [],
      "source": [
        "valid_test_essays = validation_set[\"essay\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1d8e0527",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d8e0527",
        "outputId": "87759361-1549-4ead-aa15-53a97f0288d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Word2Vec Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-d58cbba7ac4d>:16: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  word2vec_model.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ],
      "source": [
        "sentences_valid = []\n",
        "\n",
        "for valid_essay in valid_test_essays:\n",
        "    sentences_valid += tokenize_sentences(valid_essay)\n",
        "\n",
        "print(\"Training Word2Vec Model...\")\n",
        "word2vec_model = Word2Vec(\n",
        "    sentences_valid,\n",
        "    workers=num_workers,\n",
        "    vector_size=num_features,\n",
        "    min_count=min_word_count,\n",
        "    window=context,\n",
        "    sample=downsampling,\n",
        ")\n",
        "\n",
        "word2vec_model.init_sims(replace=True)\n",
        "word2vec_model.wv.save_word2vec_format(\"word2vec_model.bin\", binary=True)\n",
        "\n",
        "clean_valid_test_essays = []\n",
        "\n",
        "# Generate testing data word vectors\n",
        "for essay_text_valid in valid_test_essays:\n",
        "    clean_valid_test_essays.append(tokenize_words(essay_text_valid))\n",
        "valid_testDataVecs = generate_avg_feature_vectors(\n",
        "    clean_valid_test_essays, word2vec_model, num_features\n",
        ")\n",
        "\n",
        "valid_testDataVecs = np.array(valid_testDataVecs)\n",
        "# Reshaping test vectors to 3 dimensions (1 represents one timestep)\n",
        "valid_testDataVecs = np.reshape(\n",
        "    valid_testDataVecs, (valid_testDataVecs.shape[0], 1, valid_testDataVecs.shape[1])\n",
        ")\n",
        "\n",
        "predicted_scores_valid = lstm_model.predict(valid_testDataVecs)\n",
        "\n",
        "# Round predicted scores to the nearest integer\n",
        "predicted_scores_valid = np.around(predicted_scores_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "251a42b0",
      "metadata": {
        "id": "251a42b0"
      },
      "outputs": [],
      "source": [
        "submission = validation_set.drop([\"essay\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7fac9571",
      "metadata": {
        "id": "7fac9571"
      },
      "outputs": [],
      "source": [
        "predicted_score_series = pd.Series(\n",
        "    [score for sublist in predicted_scores_valid for score in sublist]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cfb2b69a",
      "metadata": {
        "id": "cfb2b69a"
      },
      "outputs": [],
      "source": [
        "submission = (\n",
        "    pd.concat([submission, predicted_score_series], axis=1)\n",
        "    .rename(columns={0: \"predicted_score\"})\n",
        "    .iloc[:, [2, 0, 1, 3]]\n",
        ")\n",
        "submission.to_excel(\"Submission.xlsx\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# coding: utf-8",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
